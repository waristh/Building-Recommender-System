{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import library yang dibutuhkan\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# #lakukan pembacaan dataset\n",
    "# movie_rating_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/movie_rating_df.csv') #untuk menyimpan movie_rating_df.csv\n",
    "\n",
    "# #tampilkan 5 baris teratas dari movive_rating_df\n",
    "# print(movie_rating_df.head())\n",
    "\n",
    "# #tampilkan info mengenai tipe data dari tiap kolom\n",
    "# print(movie_rating_df.info())\n",
    "\n",
    "# #Simpan actor_name.csv pada variable name_df \n",
    "# name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "\n",
    "# #Tampilkan 5 baris teratas dari name_df\n",
    "# print(name_df.head())\n",
    "\n",
    "# #Tampilkan informasi mengenai tipe data dari tiap kolom pada name_df\n",
    "# print(name_df.info())\n",
    "\n",
    "# #Menyimpan dataset pada variabel director_writers\n",
    "# director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "\n",
    "# #Manampilkan 5 baris teratas\n",
    "# print(director_writers.head())\n",
    "\n",
    "# #Menampilkan informasi tipe data\n",
    "# print(director_writers.info())\n",
    "\n",
    "# import pandas as pd\n",
    "# director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "\n",
    "# #Mengubah director_name menjadi list\n",
    "# director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "# director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "# #Tampilkan 5 data teratas\n",
    "# print(director_writers.head())\n",
    "\n",
    "# name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "# #Kita hanya akan membutuhkan kolom nconst, primaryName, dan knownForTitles\n",
    "# name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "\n",
    "# #Tampilkan 5 baris teratas dari name_df\n",
    "# print(name_df.head())\n",
    "\n",
    "# #Melakukan pengecekan variasi\n",
    "# print(name_df['knownForTitles'].apply(lambda x: len(x.split(','))).unique())\n",
    "\n",
    "# #Mengubah knownForTitles menjadi list of list\n",
    "# name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "# #Mencetak 5 baris teratas\n",
    "# print(name_df.head())\n",
    "\n",
    "# import numpy as np\n",
    "# #menyiapkan bucket untuk dataframe\n",
    "# df_uni = []\n",
    "\n",
    "# for x in ['knownForTitles']:\n",
    "#     #mengulang index dari tiap baris sampai tiap elemen dari knownForTitles\n",
    "#     idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "   \n",
    "#    #memecah values dari list di setiap baris dan menggabungkan nya dengan rows lain menjadi dataframe\n",
    "#     df1 = pd.DataFrame({\n",
    "#         x: np.concatenate(name_df[x].values)\n",
    "#     })\n",
    "    \n",
    "#     #mengganti index dataframe tersebut dengan idx yang sudah kita define di awal\n",
    "#     df1.index = idx\n",
    "#     #untuk setiap dataframe yang terbentuk, kita append ke dataframe bucket\n",
    "#     df_uni.append(df1)\n",
    "    \n",
    "# #menggabungkan semua dataframe menjadi satu\n",
    "# df_concat = pd.concat(df_uni, axis=1)\n",
    "\n",
    "# #left join dengan value dari dataframe yang awal\n",
    "# unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "\n",
    "# #select kolom sesuai dengan dataframe awal\n",
    "# unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "# print(unnested_df)\n",
    "# #select kolom sesuai dengan dataframe awal\n",
    "# unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "# print(unnested_df)\n",
    "\n",
    "\n",
    "# unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "\n",
    "# #menyiapkan bucket untuk dataframe\n",
    "# df_uni = []\n",
    "\n",
    "# for col in ['primaryName']:\n",
    "#     #agregasi kolom PrimaryName sesuai group_col yang sudah di define di atas\n",
    "#     dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "#     #Lakukan append\n",
    "#     df_uni.append(dfi)\n",
    "# df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "# df_grouped.columns = ['knownForTitles','cast_name']\n",
    "# print(df_grouped)\n",
    "\n",
    "# movie_rating_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/movie_rating_df.csv')\n",
    "\n",
    "# #join antara movie table dan cast table \n",
    "# base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "\n",
    "# #join antara base_df dengan director_writer table\n",
    "# base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "# print(base_df.head())\n",
    "\n",
    "# #Melakukan drop terhadap kolom knownForTitles\n",
    "# base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "# print(base_drop.info())\n",
    "\n",
    "# #Mengganti nilai NULL pada kolom genres dengan 'Unknown'\n",
    "# base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "\n",
    "# #Melakukan perhitungan jumlah nilai NULL pada tiap kolom\n",
    "# print(base_drop.isnull().sum())\n",
    "\n",
    "# #Mengganti nilai NULL pada kolom dorector_name dan writer_name dengan 'Unknown'\n",
    "# base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "\n",
    "# #karena value kolom genres terdapat multiple values, jadi kita akan bungkus menjadi list of list\n",
    "# base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "# #Drop kolom tconst, isAdult, endYear, originalTitle\n",
    "# base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "\n",
    "# base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "\n",
    "# base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "# print(base_drop2.head())\n",
    "\n",
    "# #Klasifikasi berdasar title, cast_name, genres, director_name, dan writer_name\n",
    "# feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
    "\n",
    "# #Tampilkan 5 baris teratas\n",
    "# print(feature_df.head())\n",
    "\n",
    "# def sanitize(x):\n",
    "#     try:\n",
    "#         #kalau cell berisi list\n",
    "#         if isinstance(x, list):\n",
    "#             return [i.replace(' ','').lower() for i in x]\n",
    "#         #kalau cell berisi string\n",
    "#         else:\n",
    "#             return [x.replace(' ','').lower()]\n",
    "#     except:\n",
    "#         print(x)\n",
    "        \n",
    "# #Kolom : cast_name, genres, writer_name, director_name        \n",
    "# feature_cols = ['cast_name','genres','writer_name','director_name']\n",
    "\n",
    "# #Apply function sanitize \n",
    "# for col in feature_cols:\n",
    "#     feature_df[col] = feature_df[col].apply(sanitize)\n",
    "\n",
    "# #kolom yang digunakan : cast_name, genres, director_name, writer_name\n",
    "# def soup_feature(x):\n",
    "#     return ' '.join(x['cast_name']) + ' ' + ' '.join(x['genres']) + ' ' + ' '.join(x['director_name']) + ' ' + ' '.join(x['writer_name'])\n",
    "\n",
    "# #membuat soup menjadi 1 kolom \n",
    "# feature_df['soup'] = feature_df.apply(soup_feature, axis=1)\n",
    "    \n",
    "# #import CountVectorizer \n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# #definisikan CountVectorizer dan mengubah soup tadi menjadi bentuk vector\n",
    "# count = CountVectorizer(stop_words='english')\n",
    "# count_matrix = count.fit_transform(feature_df['soup'])\n",
    "\n",
    "# print(count)\n",
    "# print(count_matrix.shape)\n",
    "\n",
    "# #Import cosine_similarity\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# #Gunakan cosine_similarity antara count_matrix \n",
    "# cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "# #print hasilnya\n",
    "# print(cosine_sim)\n",
    "\n",
    "# indices = pd.Series(feature_df.index, index=feature_df['title']).drop_duplicates()\n",
    "\n",
    "# def content_recommender(title):\n",
    "#     #mendapatkan index dari judul film (title) yang disebutkan\n",
    "#     idx = indices[title]\n",
    "\n",
    "#     #menjadikan list dari array similarity cosine sim \n",
    "#     #hint: cosine_sim[idx]\n",
    "#     sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "#     #mengurutkan film dari similarity tertinggi ke terendah\n",
    "#     sim_scores = sorted(sim_scores,key=lambda x: x[1],reverse=True)\n",
    "\n",
    "#     #untuk mendapatkan list judul dari item kedua sampe ke 11\n",
    "#     sim_scores = sim_scores[1:11]\n",
    "\n",
    "#     #mendapatkan index dari judul-judul yang muncul di sim_scores\n",
    "#     movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "#     #dengan menggunakan iloc, kita bisa panggil balik berdasarkan index dari movie_indices\n",
    "#     return base_df.iloc[movie_indices]\n",
    "\n",
    "# #aplikasikan function di atas\n",
    "# print(content_recommender('The Lion King'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library yang dibutuhkan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#lakukan pembacaan dataset\n",
    "movie_rating_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/movie_rating_df.csv') #untuk menyimpan movie_rating_df.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst titleType            primaryTitle           originalTitle  \\\n",
      "0  tt0000001     short              Carmencita              Carmencita   \n",
      "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
      "2  tt0000003     short          Pauvre Pierrot          Pauvre Pierrot   \n",
      "3  tt0000004     short             Un bon bock             Un bon bock   \n",
      "4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
      "\n",
      "   isAdult  startYear  endYear  runtimeMinutes                    genres  \\\n",
      "0        0     1894.0      NaN             1.0         Documentary,Short   \n",
      "1        0     1892.0      NaN             5.0           Animation,Short   \n",
      "2        0     1892.0      NaN             4.0  Animation,Comedy,Romance   \n",
      "3        0     1892.0      NaN            12.0           Animation,Short   \n",
      "4        0     1893.0      NaN             1.0              Comedy,Short   \n",
      "\n",
      "   averageRating  numVotes  \n",
      "0            5.6      1608  \n",
      "1            6.0       197  \n",
      "2            6.5      1285  \n",
      "3            6.1       121  \n",
      "4            6.1      2050  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 751614 entries, 0 to 751613\n",
      "Data columns (total 11 columns):\n",
      "tconst            751614 non-null object\n",
      "titleType         751614 non-null object\n",
      "primaryTitle      751614 non-null object\n",
      "originalTitle     751614 non-null object\n",
      "isAdult           751614 non-null int64\n",
      "startYear         751614 non-null float64\n",
      "endYear           16072 non-null float64\n",
      "runtimeMinutes    751614 non-null float64\n",
      "genres            486766 non-null object\n",
      "averageRating     751614 non-null float64\n",
      "numVotes          751614 non-null int64\n",
      "dtypes: float64(4), int64(2), object(5)\n",
      "memory usage: 63.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#tampilkan 5 baris teratas dari movive_rating_df\n",
    "print(movie_rating_df.head())\n",
    "\n",
    "#tampilkan info mengenai tipe data dari tiap kolom\n",
    "print(movie_rating_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       nconst          primaryName birthYear deathYear  \\\n",
      "0   nm1774132    Nathan McLaughlin      1973        \\N   \n",
      "1  nm10683464        Bridge Andrew        \\N        \\N   \n",
      "2   nm1021485    Brandon Fransvaag        \\N        \\N   \n",
      "3   nm6940929   Erwin van der Lely        \\N        \\N   \n",
      "4   nm5764974  Svetlana Shypitsyna        \\N        \\N   \n",
      "\n",
      "                    primaryProfession                           knownForTitles  \n",
      "0  special_effects,make_up_department  tt0417686,tt1713976,tt1891860,tt0454839  \n",
      "1                               actor                                tt7718088  \n",
      "2                       miscellaneous                                tt0168790  \n",
      "3                       miscellaneous                                tt4232168  \n",
      "4                             actress                                tt3014168  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      "nconst               1000 non-null object\n",
      "primaryName          1000 non-null object\n",
      "birthYear            1000 non-null object\n",
      "deathYear            1000 non-null object\n",
      "primaryProfession    891 non-null object\n",
      "knownForTitles       1000 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 47.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Simpan actor_name.csv pada variable name_df \n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "\n",
    "#Tampilkan 5 baris teratas dari name_df\n",
    "print(name_df.head())\n",
    "\n",
    "#Tampilkan informasi mengenai tipe data dari tiap kolom pada name_df\n",
    "print(name_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst                   director_name  \\\n",
      "0  tt0011414                  David Kirkland   \n",
      "1  tt0011890               Roy William Neill   \n",
      "2  tt0014341  Buster Keaton,John G. Blystone   \n",
      "3  tt0018054                Cecil B. DeMille   \n",
      "4  tt0024151                     James Cruze   \n",
      "\n",
      "                                       writer_name  \n",
      "0                          John Emerson,Anita Loos  \n",
      "1     Arthur F. Goodrich,Burns Mantle,Mary Murillo  \n",
      "2  Jean C. Havez,Clyde Bruckman,Joseph A. Mitchell  \n",
      "3                                Jeanie Macpherson  \n",
      "4                 Max Miller,Wells Root,Jack Jevne  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 986 entries, 0 to 985\n",
      "Data columns (total 3 columns):\n",
      "tconst           986 non-null object\n",
      "director_name    986 non-null object\n",
      "writer_name      986 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 23.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Menyimpan dataset pada variabel director_writers\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "\n",
    "#Manampilkan 5 baris teratas\n",
    "print(director_writers.head())\n",
    "\n",
    "#Menampilkan informasi tipe data\n",
    "print(director_writers.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst                      director_name  \\\n",
      "0  tt0011414                   [David Kirkland]   \n",
      "1  tt0011890                [Roy William Neill]   \n",
      "2  tt0014341  [Buster Keaton, John G. Blystone]   \n",
      "3  tt0018054                 [Cecil B. DeMille]   \n",
      "4  tt0024151                      [James Cruze]   \n",
      "\n",
      "                                         writer_name  \n",
      "0                         [John Emerson, Anita Loos]  \n",
      "1   [Arthur F. Goodrich, Burns Mantle, Mary Murillo]  \n",
      "2  [Jean C. Havez, Clyde Bruckman, Joseph A. Mitc...  \n",
      "3                                [Jeanie Macpherson]  \n",
      "4               [Max Miller, Wells Root, Jack Jevne]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "\n",
    "#Mengubah director_name menjadi list\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "#Tampilkan 5 data teratas\n",
    "print(director_writers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       nconst          primaryName                           knownForTitles\n",
      "0   nm1774132    Nathan McLaughlin  tt0417686,tt1713976,tt1891860,tt0454839\n",
      "1  nm10683464        Bridge Andrew                                tt7718088\n",
      "2   nm1021485    Brandon Fransvaag                                tt0168790\n",
      "3   nm6940929   Erwin van der Lely                                tt4232168\n",
      "4   nm5764974  Svetlana Shypitsyna                                tt3014168\n"
     ]
    }
   ],
   "source": [
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "#Kita hanya akan membutuhkan kolom nconst, primaryName, dan knownForTitles\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "\n",
    "#Tampilkan 5 baris teratas dari name_df\n",
    "print(name_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 2 3]\n",
      "       nconst          primaryName  \\\n",
      "0   nm1774132    Nathan McLaughlin   \n",
      "1  nm10683464        Bridge Andrew   \n",
      "2   nm1021485    Brandon Fransvaag   \n",
      "3   nm6940929   Erwin van der Lely   \n",
      "4   nm5764974  Svetlana Shypitsyna   \n",
      "\n",
      "                                 knownForTitles  \n",
      "0  [tt0417686, tt1713976, tt1891860, tt0454839]  \n",
      "1                                   [tt7718088]  \n",
      "2                                   [tt0168790]  \n",
      "3                                   [tt4232168]  \n",
      "4                                   [tt3014168]  \n"
     ]
    }
   ],
   "source": [
    "#Melakukan pengecekan variasi\n",
    "print(name_df['knownForTitles'].apply(lambda x: len(x.split(','))).unique())\n",
    "\n",
    "#Mengubah knownForTitles menjadi list of list\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "#Mencetak 5 baris teratas\n",
    "print(name_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         nconst                primaryName knownForTitles\n",
      "0     nm1774132          Nathan McLaughlin      tt0417686\n",
      "0     nm1774132          Nathan McLaughlin      tt1713976\n",
      "0     nm1774132          Nathan McLaughlin      tt1891860\n",
      "0     nm1774132          Nathan McLaughlin      tt0454839\n",
      "1    nm10683464              Bridge Andrew      tt7718088\n",
      "2     nm1021485          Brandon Fransvaag      tt0168790\n",
      "3     nm6940929         Erwin van der Lely      tt4232168\n",
      "4     nm5764974        Svetlana Shypitsyna      tt3014168\n",
      "5     nm8621807                Utku Arslan      tt5493404\n",
      "5     nm8621807                Utku Arslan      tt7661932\n",
      "5     nm8621807                Utku Arslan      tt0845088\n",
      "5     nm8621807                Utku Arslan      tt9278408\n",
      "6     nm0415875               Mihály Jakab      tt0242160\n",
      "7     nm7082726             Ernesto Ballén      tt8696516\n",
      "7     nm7082726             Ernesto Ballén      tt6407610\n",
      "7     nm7082726             Ernesto Ballén      tt2707408\n",
      "7     nm7082726             Ernesto Ballén      tt4392976\n",
      "8     nm5903442                  Jen Brown      tt3145724\n",
      "9     nm1744604        Tatyana Kuzmichyova      tt0420982\n",
      "9     nm1744604        Tatyana Kuzmichyova      tt1186366\n",
      "9     nm1744604        Tatyana Kuzmichyova      tt0417552\n",
      "9     nm1744604        Tatyana Kuzmichyova      tt0847880\n",
      "10    nm8581827                 Joel Capps      tt6245544\n",
      "11    nm4404596               Roger Caadan      tt1483429\n",
      "12    nm1669765                 Jim Boutet      tt0414476\n",
      "12    nm1669765                 Jim Boutet      tt0106067\n",
      "13    nm3211206                Mi Young Jo      tt0101178\n",
      "14    nm3123793             Maksim Romanov      tt8777220\n",
      "14    nm3123793             Maksim Romanov      tt1075829\n",
      "15    nm8651439        Aleksandr Tretyakov      tt5528188\n",
      "..          ...                        ...            ...\n",
      "983   nm6771564              Do-Kyeong Lee      tt2797106\n",
      "983   nm6771564              Do-Kyeong Lee      tt8750956\n",
      "984   nm4462830  Christopher Bryant Tucker      tt1934293\n",
      "985   nm2753117           Alexander Lorenz      tt1074607\n",
      "986   nm2573036       David Jason Pressman      tt0108894\n",
      "987   nm2279830              Judith Allard      tt0145529\n",
      "988   nm2264406            Jared R. Morris      tt0384766\n",
      "988   nm2264406            Jared R. Morris      tt4851552\n",
      "988   nm2264406            Jared R. Morris      tt2229123\n",
      "988   nm2264406            Jared R. Morris      tt0387199\n",
      "989   nm7677943               Carlos Denis      tt5140670\n",
      "990   nm7390826              Darlene Huynh      tt4771886\n",
      "991   nm5251983                David Hague      tt2239078\n",
      "992   nm1987981       Henry Mercedes Vales      tt8979132\n",
      "992   nm1987981       Henry Mercedes Vales      tt0801017\n",
      "992   nm1987981       Henry Mercedes Vales      tt8257760\n",
      "992   nm1987981       Henry Mercedes Vales      tt2238964\n",
      "993   nm8270190                 Lilin Lace      tt5523166\n",
      "994   nm7383079            Francois Landry      tt4762718\n",
      "995   nm7596674               Paul Whitrow      tt4118352\n",
      "995   nm7596674               Paul Whitrow      tt9104322\n",
      "995   nm7596674               Paul Whitrow      tt4447090\n",
      "995   nm7596674               Paul Whitrow      tt4892804\n",
      "996   nm5938546                Wendy Ponce      tt2125666\n",
      "997   nm2101810               Ans Brugmans      tt0488280\n",
      "998   nm5245804              Eliza Jenkins      tt1464058\n",
      "999   nm0948460                 Greg Yolen      tt0436869\n",
      "999   nm0948460                 Greg Yolen      tt0476663\n",
      "999   nm0948460                 Greg Yolen      tt0109723\n",
      "999   nm0948460                 Greg Yolen      tt0364484\n",
      "\n",
      "[1918 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#menyiapkan bucket untuk dataframe\n",
    "df_uni = []\n",
    "\n",
    "for x in ['knownForTitles']:\n",
    "    #mengulang index dari tiap baris sampai tiap elemen dari knownForTitles\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "   \n",
    "   #memecah values dari list di setiap baris dan menggabungkan nya dengan rows lain menjadi dataframe\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    \n",
    "    #mengganti index dataframe tersebut dengan idx yang sudah kita define di awal\n",
    "    df1.index = idx\n",
    "    #untuk setiap dataframe yang terbentuk, kita append ke dataframe bucket\n",
    "    df_uni.append(df1)\n",
    "    \n",
    "#menggabungkan semua dataframe menjadi satu\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "\n",
    "#left join dengan value dari dataframe yang awal\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "\n",
    "#select kolom sesuai dengan dataframe awal\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "print(unnested_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "\n",
    "#menyiapkan bucket untuk dataframe\n",
    "df_uni = []\n",
    "\n",
    "for col in ['primaryName']:\n",
    "    #agregasi kolom PrimaryName sesuai group_col yang sudah di define di atas\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    #Lakukan append\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "print(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rating_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/movie_rating_df.csv')\n",
    "\n",
    "#join antara movie table dan cast table \n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "\n",
    "#join antara base_df dengan director_writer table\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "print(base_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Melakukan drop terhadap kolom knownForTitles\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "print(base_drop.info())\n",
    "\n",
    "#Mengganti nilai NULL pada kolom genres dengan 'Unknown'\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "\n",
    "#Melakukan perhitungan jumlah nilai NULL pada tiap kolom\n",
    "print(base_drop.isnull().sum())\n",
    "\n",
    "#Mengganti nilai NULL pada kolom dorector_name dan writer_name dengan 'Unknown'\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "\n",
    "#karena value kolom genres terdapat multiple values, jadi kita akan bungkus menjadi list of list\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop kolom tconst, isAdult, endYear, originalTitle\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "print(base_drop2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Klasifikasi berdasar title, cast_name, genres, director_name, dan writer_name\n",
    "feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
    "\n",
    "#Tampilkan 5 baris teratas\n",
    "print(feature_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sanitize(x):\n",
    "    try:\n",
    "        #kalau cell berisi list\n",
    "        if isinstance(x, list):\n",
    "            return [i.replace(' ','').lower() for i in x]\n",
    "        #kalau cell berisi string\n",
    "        else:\n",
    "            return [x.replace(' ','').lower()]\n",
    "    except:\n",
    "        print(x)\n",
    "        \n",
    "#Kolom : cast_name, genres, writer_name, director_name        \n",
    "feature_cols = ['cast_name','genres','writer_name','director_name']\n",
    "\n",
    "#Apply function sanitize \n",
    "for col in feature_cols:\n",
    "    feature_df[col] = feature_df[col].apply(sanitize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kolom yang digunakan : cast_name, genres, director_name, writer_name\n",
    "def soup_feature(x):\n",
    "    return ' '.join(x['cast_name']) + ' ' + ' '.join(x['genres']) + ' ' + ' '.join(x['director_name']) + ' ' + ' '.join(x['writer_name'])\n",
    "\n",
    "#membuat soup menjadi 1 kolom \n",
    "feature_df['soup'] = feature_df.apply(soup_feature, axis=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import CountVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#definisikan CountVectorizer dan mengubah soup tadi menjadi bentuk vector\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(feature_df['soup'])\n",
    "\n",
    "print(count)\n",
    "print(count_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Gunakan cosine_similarity antara count_matrix \n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "#print hasilnya\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(feature_df.index, index=feature_df['title']).drop_duplicates()\n",
    "\n",
    "def content_recommender(title):\n",
    "    #mendapatkan index dari judul film (title) yang disebutkan\n",
    "    idx = indices[title]\n",
    "\n",
    "    #menjadikan list dari array similarity cosine sim \n",
    "    #hint: cosine_sim[idx]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    #mengurutkan film dari similarity tertinggi ke terendah\n",
    "    sim_scores = sorted(sim_scores,key=lambda x: x[1],reverse=True)\n",
    "\n",
    "    #untuk mendapatkan list judul dari item kedua sampe ke 11\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    #mendapatkan index dari judul-judul yang muncul di sim_scores\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    #dengan menggunakan iloc, kita bisa panggil balik berdasarkan index dari movie_indices\n",
    "    return base_df.iloc[movie_indices]\n",
    "\n",
    "#aplikasikan function di atas\n",
    "print(content_recommender('The Lion King'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
